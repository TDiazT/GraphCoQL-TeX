
\section{Introduction}

GraphQL is a technology-agnostic framework that provides a common language to define interfaces to services' data and to query them. It has been mainly proposed as a new alternative to RESTful Web Services. After being used internally in Facebook for three years, in 2015 they released a specification and a reference implementation. Since its release, GraphQL has seen a huge increase in popularity, with major firms such as Coursera, Github and Airbnb incorporating it to their services. Early on 2019, it became an independent foundation, separating itself from Facebook. Some of its strong appeals are that many REST requests can be replaced by a single GraphQL query and that queries follow a ``what you ask is what you get'' spirit. This means that one can be very precise with the data requested and the response will look very similar to the query.

GraphQL has a specification that describes its main components. We will refer to it as the \spec throughout the paper. This document includes definitions for the query language and validation processes, among other things. The specification actively undergoes revisions, with an open working group that meets monthly to discuss related issues and improvements. These include extending the language to support new features or fix possible ambiguities present in the document. This is because the document is written in plain english and does not include a rigorous formalization of its inner mechanics and limitations.
% There is also a project to define CATs\footnote{Compatibility Acceptance Tests} for the different languages and frameworks that implement GraphQL\td{Not sure if this should go or where. It may serve as a link to "why of GraphCoQL"}.

Hartig and PÃ©rez proposed the first (and so far only) formalization of GraphQL and its semantics~\cite{gqlph}. They then use it to prove some complexity boundaries for GraphQL queries. These results are based off two major statements. The first one is that ``\textit{for every query $\varphi$ that conforms to a schema $\mathcal{S}$ there exists a {\normalfont non-redundant} query $\varphi$' in {\normalfont ground-typed normal form} such that $\varphi \equiv \varphi$'}''. The second one is that for queries that are \textit{non-redundant} and in \textit{ground-typed normal form}, it is possible to define a simplified version of the semantics which is equal to the original.
For the former, they propose equivalence rules to transform queries but do not actually provide proof that the normalization is correct and that it preserves the semantics. The latter is also missing its proof. Since both are fundamental for their complexity results, we believe it is essential to tackle them.

%We will refer to it as \HP throughout the paper. They define the semantics of GraphQL by using a graph as the underlying data model over which queries are evaluated. \td{rewrite} define the normalization transformation, which results in \textit{non-redundant} queries in \textit{ground-typed normal form}.
% This normalization process is essential for proving complexity boundaries for GraphQL queries, because it allows simplifying the semantics and.

On another note, we believe that GraphQL is still a very young and active technology which could benefit greatly by having its specification mechanically verified from its early stages. Its scope is not so vast that it cannot be formalized, and it is still growing and with open questions. It currently has a reference implementation\footnote{https://github.com/graphql/graphql-js}, written in Javascript, which could be improved by introducing a formally verified one. We will refer to it as \textit{GraphQLJs} throughout the document.

 We therefore decided to implement \textit{GraphCoQL}\footnote{The ``CoQ'' part is pronounced as ``Coq'', not pronouncing the ``Q'' separately as in ``GraphQL''.}, which formalizes GraphQL and its semantics in Coq. Our intention is that it can serve as a starting point towards fully formalizing GraphQL and extracting it to be its official reference implementation.  Transformations over queries, such as \HP's normalization, can then be completely specified and proven correct, as well as possible extensions to the language.

To address the trustworthiness of our implementation, GraphCoQL tries to match the \spec's definitions whenever possible. This provides a component of trustworthiness given by an eyeball correspondence, following the examples of X, Y, Z. We also test our implementation with examples from the \spec but a more thorough comparison should be made against \textit{GraphQLJs} and a bigger test suite.

With respect to the semantics itself, we follow a mixed approach between the \spec and \HP. The semantics are defined in a graph setting, as is in \HP, but the algorithm can be traced more closely to the \spec's. One of the biggest difference between both approaches (besides the graph model) is that the \spec performs a processing of queries during the evaluation, while \HP performs a post-processing of the responses generated. We took the mixed approach, which brings out some benefits as well as some limitations, which we discuss further in a following section.

%\td{Rewrite} When it comes to the underlying data model, we follow \HP and define our semantics in a graph setting. We are also interested in defining the properties and transformation rules defined by \HP. These definitions and their proofs of correctness are fundamental in the posterior results they obtain. This served as a particularly interesting first case study for our system, to establish that we can actually reason about GraphQL and that theirs results were based off correct assumptions. This allows us to, hopefully, anticipate that other transformations may also be defined and proven correct in GraphCoQL.

Finally, in regards to extraction and the code itself, GraphCoQL is not currently extracted to any language. However, we made heavy use of SSReflect and their mindset of using boolean reflection as much as possible. We were first motivated to use it to define the data model and try to narrow our scope to finite types, as was used by (Veronique, Ev, Emilio, Dumbrava). In the end, we did not use any of it but the computational aspect of SSReflect was kept, as it facilitated developing the proofs. This same element is what makes us believe that extraction should not be hard.
A final note on the implementation is the use of the \textit{Equations}\footnote{http://mattam82.github.io/Coq-Equations/} library to define non-structural recursive functions. Other libraries, such as \textit{Function} and \textit{Program} did not provide sufficient tools to handle rewriting and inductive reasoning about our definitions, which \textit{Equations} incredibly facilitates. We therefore found it crucial in our development.

\subsubsection*{Contributions}
The main contributions of this work are:
\begin{enumerate}
    \item The first mechanized formalization of GraphQL, including the definition for schema's DSL, query definition, schema and query validation, and its semantics over a graph data model. \td{rephrase} The implementation is done in Coq.
    \item Detection and correction of unsound definitions in \HP.
    \item The implementation of a normalization function with proofs of its correctness and preservation of semantics. This is a result used by \HP to prove complexity boundaries about GraphQL queries.
    \item Proof of equivalence between the semantics and a simplified version. This is also an important result for posterior analysis made in \HP.

\end{enumerate}

\subsubsection*{Structure of this paper}

We first begin by gently and briefly introducing GraphQL in Section \ref{sec:bg}, which we do by means of an example. Then, in Section \ref{sec:form}, we describe the basic building blocks of our Coq formalization. This includes the definition of a GraphQL schema, the graph data model, queries and their semantics. Section \ref{sec:norm} describes the normalization process and proofs of its correctness and preservation of semantics. We finalize that section with the definition of the simplified semantics, as described in \HP, and a proof of equivalence between the semantics defined in Section \ref{sec:form} and the simplified one. In Section \ref{sec:valid}, we describe some of the work we did to validate our implementation and finally Section \ref{sec:related} and \ref{sec:future} we discuss related and future work.\td{include note on code as anonymous supplementary material}
