% !TEX root = ./main.tex
\section{Query Transformation: Normalization}\label{sec:norm}

To illustrate how \gcoql can be used to reason about query transformations, we study the {\em normalization} process proposed by Hartig and Pérez (\HP)~\cite{gqlph}, which is fundamental for the complexity results they prove.
%
Recall that these results are based on two premises: {\em a)} every query can be normalized to a semantically-equivalent query; {\em b)} on such queries, one can use a simplified, but equivalent, evaluation function. For normalization,  \HP provide a set of equivalence rules, which serve as rewriting rules\et{directedness?}\et{equivalence rules are not directed, rewriting rules should be (otherwise it wouldn't be terminating)}, but they do not prove the correctness of rewriting\et{explain: what does "correctness of rewriting" mean?}. Likewise, they do not prove the equivalence of the semantics when applied to normalized queries.

In this section, we use \gcoql to define the property of being in \textit{normal form}, the normalization procedure, as well as proving both correctness and semantic equivalence. Finally, we define a new simplified semantics and prove the equivalence to the original semantics from \S~\ref{subsec:semantics}.

It is worth mentioning that most of our formalization effort was devoted to defining and establishing the correctness of this normalization procedure. In terms of code, definitions are coded in approximately $350$ lines, while proofs amount to around $1,200$ lines. The complete definitions and proofs can be found in the files \texttt{QueryNormalForm.v} and \texttt{QueryNormalFormLemmas.v}. \et{does that include point b)?}\et{see the first paragraph of this section, I've introduced labels}

\subsection{Normal form}

The notion of \textit{normal form} introduced by Hartig and Pérez consists of the conjunction of two properties: being \textit{grounded} and being \textit{non-redundant}.
\HP refers to the former as being in \textit{ground-typed normal form}. %\et{remove/why is that confusing?} We believe this naming is confusing so we decide to rename it to the previously described property.

%\et{skip/move} Similarly to what is described in Section~\ref{subsec:query}, the normalization process requires information on the type in context where the queries might be defined. This is crucial as it guides the process on how queries are transformed.

% Throuhgout our development, we noticed that this definition given by \cite{gqlph} was too general when proving correctness of our normalization procedure. In particular, the definition states that the subqueries of a field selection can be either fields or fragments. This means that if there are two field selections with the same response name, one may have subqueries consisting of fields, while the other contains only inline fragments. This would cause issues when trying to remove redundancies in queries because one could not directly establish if the resulting queries satisfied the property.
\subsubsection*{Groundedness}
%\et{should it be "groundedness"? (being bounded is boundedness, being rounded is roundedness, etc.)}
Informally, the \textit{groundedness} property refers to whether queries are completely specified down to object types.  Consider the queries below, based on the schema from Figure~\ref{fig:schema_ex}\td{Might be a stretch to pull that figure from the beginning}, which request the name of an animal. The query to the left is not grounded because the field \texttt{name} is made over the abstract type \texttt{Animal} type. In contrast, the query on the right is requesting the same information, but it is grounded because it fully specifies the (concrete) object types on which it requests the information.
\td{Align to top or as it is? Aligning to top leaves a huge empty space :/}
\begin{minipage}{.25\textwidth}
\begin{minted}[escapeinside=||, mathescape=true]{js}
// Not grounded query
query {
  goodboi {
    name
  }
}
\end{minted}
\end{minipage}%
\begin{minipage}{.25\textwidth}
\begin{minted}[escapeinside=||, mathescape=true]{js}
// Grounded query
query {
  goodboi {
    |$\ldots$| on Dog {
	  name
    }
    |$\ldots$| on Pig {
      name
    }
  }	
}
\end{minted} 
\end{minipage}

%\et{verbose/repetitive} The main idea is that if a query is performed over an object type then the query should only be composed of field selections. In contrast, if the query is over an abstract type, then it should only be composed of inline fragments that specify the selections down to the object subtypes. In the former case, it does not make sense to use fragments to further specify a query because it is not possible to be more specific when querying an object. Meanwhile, in the latter case the query should clearly state what is being requested from each concrete subtype. 

\begin{definition}
A \gql query $\varphi$ is \textit{grounded} if it satisfies the following conditions, where \texttt{ty} is the type in scope.
\begin{itemize}
	\item If \texttt{ty} is an object type, then $\varphi$ contains only fields.
	\item If \texttt{ty} is an abstract type, then $\varphi$ contains only inline fragments whose type conditions are object types.
	\item Subqueries of $\varphi$ are \textit{grounded} w.r.t. to the field's return type or the fragments type condition.
\end{itemize}
\end{definition}

This definition of groundedness differs slightly from that of \HP \et{how is it different? why?}\td{See response in Zulip}\et{you can't just say that "it differs slightly" to the reader---you're  saying too much or too little. You can be approximate here and then clarify in the discussion section, or mention it here and saying that you'll expand on this in that later section}\et{I'd suggest to give you 2-3 lines to mention the main differences and put a forward ref to \S5)} nevertheless, we prove that our definition still implies being in ground-typed normal form \et{if you prove that it means you have also formalized the exact def from HP? so?}.

\begin{minted}{coq}
Lemma are_grounded_in_ground_typed_nf (s : wfGraphQLSchema)
                                      (type_in_scope : Name)
                                      (queries : seq Query) :
        are_grounded s type_in_scope queries ->
        are_in_ground_typed_nf s queries.
\end{minted}

\et{why this plural formulation?}\et{you must be kidding in your response...}\et{the question is why you don't have a lemma for a single query (and then if you need to check a sequence, you map that singular property over the sequence)}\et{notice that 4.1 talks about "*a* query is grounded"}
\et{type-in-scope is a (too) long variable name - you can use use "ts" throughout, just explaining clearly when you first use it}
%\et{watch out the argument was called type-in-scope while its used as ty.}

\et{why do we care about this lemma instead of the definition of is-grounded?}

\subsubsection*{Non-redundancy}

Informally, 
% \et{bad phrasing: what is "non-redundant" is a "query", not "whether there are no queries"} the notion of non-redundancy refers to whether there are no queries that may produce repeated results. 
a non-redundant query is a query that does not produce repeated results.
For example, consider the two queries below:
%\td{Should this be another figure?}\et{do the same as you do for groundedness -- better to just inline if there are no references from other parts of the paper}\et{use the same trick with comments to indicate grounded/ungrounded}

\begin{minipage}[t]{.25\textwidth}
\begin{minted}[escapeinside=||, mathescape=true]{js}
// Redundant query
query {
    goodboi {
        name
        name
        |$\ldots$| on Dog {
            name
        }
        |$\ldots$| on Dog {
            friends { |$\ldots$| }
}  }  }
\end{minted}
\end{minipage}%
\begin{minipage}[t]{.25\textwidth}
\begin{minted}[escapeinside=||, mathescape=true]{js}
// Non-redundant query
query {
    goodboi {
        |$\ldots$| on Dog {
            name
        }
        |$\ldots$| on Pig {
            name
        }
    } 
}
\end{minted} 
\end{minipage}
%\et{fix layout}

The query on the left requests the field \texttt{name} twice to the same type, and uses two fragments with the same type condition. If no collection and merger of fields is performed during the evaluation, this will produce two values with key \texttt{name}. Meanwhile, the query on the right requests information about each type only once. It is important to notice that, even though it requests the field \texttt{name} in both, this is considered not redundant because only one fragment will actually be executed at a time, 
depending on the concrete object value that is used to evaluate the query.

\begin{definition}
A \gql query $\varphi$ is \textit{non-redundant} if it satisfies the following conditions:
\begin{itemize}
    \item There is at most one field selection with a given response name, for a particular depth of the query tree.

    \item There is at most one inline fragment with a given type condition, for a particular depth of the query tree.
    
    \item Subqueries are non-redundant.
\end{itemize}
\end{definition}

Our definition of non-redundancy assumes that the queries are grounded \et{maybe the Coq definition, but not the definition above!}, much like \HP, mainly to simplify the implementation. The difficulty arises from using inline fragments and comparing their contents appropriately. This difficulty is further increased by the fact that the \spec currently allows using fragments that can possibly span over several unrelated types\footnote{https://graphql.github.io/graphql-spec/June2018/\#sec-Fragment-spread-is-possible}\footnote{https://github.com/graphql/graphql-spec/issues/367}\footnote{Example of inline fragments spanning to unrelated types - https://tinyurl.com/y4uxz3gu}\td{Should we expand on this somewhere?}.

\subsection{Normalization procedure}\label{subsec:normalization}

The normalization procedure can be understood as a form of abstract interpretation\et{before, tell us what it does}, which evaluates queries using only static information about the type in context. Figure~\ref{fig:normalize} displays pseudocode describing the process when the head of the list of queries is a field selection with subqueries. We do not include the complete definition because of space limitations, but the complete definition can be found in the file \texttt{QueryNormalForm.v}.


\begin{figure*}[h]
\centering
\begin{tabular}{c}
\begin{lstlisting}[
mathescape=true,
style=code]
(*@\textbf{BEGIN}@*) normalize
 (*@\textbf{INPUT}@*) schema, type_in_context, queries
 CASE queries WITH
  | nil => nil
  | CONS (response_name [args] { subqueries }) queries => 
    LET return_type := LOOKUP (schema, type_in_scope, response_name) IN
    LET collected := COLLECT (schema, response_name, type_in_scope, queries) IN
    LET merged := CONCAT (subqueries,  MERGE collected) IN
    LET filtered := FILTER (response_name, queries) IN
    
    IF IS_OBJECT_TYPE (schema, return_type) THEN 
     CONS
      response_name [args] { normalize (schema, return_type, merged)} 
      normalize (schema, type_in_scope, filtered)
    ELSE 
     LET subtypes := SUBTYPES (schema, type_in_scope) IN
     CONS
      response_name [args] { MAP ($\lambda$ subtype => INLINE (subtype, normalize (schema, subtype, merged))) subtypes } 
      normalize (schema, type_in_scope, filtered)
     
  | ...
(*@\textbf{END}@*) normalize
\end{lstlisting}
\end{tabular}
\caption{Pseudocode for the normalization procedure, showcasing field selections with subqueries.\td{Should we add brief defs. of COLLECT, MERGE, etc.?}}
\label{fig:normalize}
\end{figure*}

The complete normalization process is actually composed of two separate functions; \texttt{normalize}, which performs all the actual work but under the assumption that the type in context is an object type, and \texttt{normalize\_queries}, which makes no assumption but only pipes the work\et{?}\td{Don't know what else to add. One function does all the work, the other one just pipes the work the other, based on the type in context} \et{my question is because the expression "pipe the work" is not clear/correct} to the former. The main process can be informally described as consisting of two subprocesses that deal with the two aforementioned properties.\et{which? (merging, mentioned below, was not mentioned above)}
\iffalse
\begin{itemize}
    \item Grounding: Selections are either wrapped with inline fragments or lifted from an inline fragment.

    \item Merging: Fields with the same response name have their subqueries merged into a single selection.
    
    %Whenever a field is encountered, the procedure tries to find all fields with the same response name and merge their subqueries. It then proceeds to remove them from the list to ensure \textit{non-redundancy}. Comparing it to the the semantics, this is equivalent to the case when we evaluate a field and collect similar ones.
    
    %Since it is assumed that the type in context is an Object type, it will try to transform the query such that there are only fields left. This means it will try to get rid of inline fragments and lift their subqueries as much as possible. Much like if we were standing on a node in the graph, we only evaluate fragments and subqueries that make sense for that node's type (which is an Object type). In the case of fields, it will first check on its return type. If it is an abstract type, then it will create a cover of all possible concrete subtypes of the abstract type, by wrapping the subqueries with inline fragments. Otherwise, it will proceed recursively. Once again, this is like finding the neighbors of a node. Since a priori it doesn't know the neighboring nodes that may be encountered, the procedure anticipates all possible scenarios.
\end{itemize}
\fi

The first subprocess\et{name it} tackles\et{you "tackle" too much -- it's a vague term, be precise. What is "tackling the groundedness"? is it "transforming a query to an equivalent grounded one"? then say so. You can look for "tackle" in the whole paper and do the exercise of finding the thing tackle stands for.} the groundedness of queries, and corresponds to the \texttt{if-else} block \et{lines?} as well as the mapping in line 19 of Figure~\ref{fig:normalize}. The grounding is done by either wrapping selections with inline fragments, whenever the type in context is an abstract type, or by lifting nested selections from inside fragments, whenever their type conditions are compatible with the object type in context\td{This is related to the fact that \gql allows invalid fragments}. This process can be illustrated with the example for Figure~\ref{fig:grounded}. \et{there is no space for repetition: this is just saying that normalizing grounds, which we know already. So what is worth saying? (go the point, don't repeat)} Once again, the query to the left is not grounded since it requests the name of an animal without being specific down to the object types. The normalization process will then produce the query to the right, by wrapping the selection using fragments with the subtypes of the \texttt{Animal} type, namely \texttt{Dog} and \texttt{Pig}.

\iffalse
\td{This is the same example as above, so it can be reused}
\begin{minted}[escapeinside=||, mathescape=true]{js}
// Not grounded query
query {
    goodboi {
        name
    }
}
// Normalized query
query {
    goodboi {
        |$\ldots$| on Dog {
	    name
	}
	|$\ldots$| on Pig {
	    name
	}
    }	
}
\end{minted} 
\fi


\td{Unnecessary?} \et{yeah, I think all this is taking too much space for the actual technical content and insights it provides. Think of a more concise way to describe normalization, ie. by guiding the reader walk through FIgure 9}\et{examples are not necessary, you illustrated before when introducing the notions} \et{for now, I'm skipping the rest of 4.2, jumping to 4.3}
Next, to tackle inline fragments that are unnecessary or that specialize selections in the context of an object type, let us consider the following queries. The first query includes two fragments that are not necessary; a fragment with type condition \texttt{Query} and one with type condition \texttt{Animal}. The procedure eliminates both fragments, by lifting the subqueries.

\begin{minted}[escapeinside=||, mathescape=true]{js}
// Not grounded query
query {
    |$\ldots$| on Query {
        goodboi {
            |$\ldots$| on Dog {
	        |$\ldots$| on Animal {
		    name
		}
	    }
	}
}
// Normalized query
query {
    goodboi {
        |$\ldots$| on Dog {
	    name
	}
    }	
}
\end{minted} 

When it comes to removing redundancies in a query, there is a second subprocess that handles it, which roughly correspond to lines 7-9 in Figure~\ref{fig:normalize}. The process collects fields that share the same response name, merging their subqueries into a single selection. For example, the first query below is redundant since it requests the same \texttt{goodboi} field twice, and the subqueries in both cases also contain repeated \texttt{name} selections. The normalization process then merges the selections with the same response name, leaving only one occurrence of each case.

\begin{minipage}[t]{.25\textwidth}
\begin{minted}[escapeinside=||, mathescape=true]{js}
// Redundant query
query {
    goodboi {
        name
    }
    goodboi { 
 	name
    } 
}
\end{minted}
\end{minipage}%
\begin{minipage}[t]{.25\textwidth}
\begin{minted}[escapeinside=||, mathescape=true]{js}

// Normalized query
query {
    goodboi {
        |$\ldots$| on Dog {
	    name
	}
	|$\ldots$| on Pig {
	    name
	}
    }	
}
\end{minted} 
\end{minipage}

% With this definition, we define a second one, which makes no assumption on the type in context. This procedure only checks what kind of type it receives and either pipes the job to the previous one, or covers the queries with the possible concrete subtypes (and then pipes the work to the previous definition).

\iffalse
\begin{minted}{coq}
 Definition normalize_queries (s : wfGraphQLSchema)
                             (type_in_scope : Name)
                             (queries : seq Query) :
                                         seq Query :=
    if is_object_type s type_in_scope then
        normalize s type_in_scope queries
    else
        [seq on t { normalize s t queries } |
            t <- get_possible_types s type_in_scope].

\end{minted}
\fi

As a final note, it is worth mentioning that the subprocesses mentioned are not defined as separate functions, but occur interleaved in the normalization function. As a consequence, the definition is highly\td{?} non-structural but can be easily expressed using the Equations library. The  similarity between the normalization function and the semantics also eases reasoning about the preservation of the semantics. \td{Mention something about how we first split the definition into these 2 subprocesses but ended up being harder to reason about?}

We now move onto proving correctness of the normalization procedure and the preservation of the semantics.


% Finally, with these properties and definitions we prove the premises proposed by \HP. We leave that discussion, about \HP's approach and ours, to Section~\ref{subsec:discussion}.

\subsection{Proofs of correctness and preservation}

\et{the name of this "property/ies" keeps changing. Pick one, and use it throughout (ie. intro, beginning of 4)}

%As described initially in this paper \et{you recalled it in the header of 4, no need to say it again}, \HP base the complexity results over \gql queries on two premises; queries can be normalized, preserving their semantics, and there is an equivalent simplified function to evaluate queries in normal form. 
We now prove that any query can be normalized to an equivalent query, by 
proving the correctness of our normalization procedure. Recall that this key result is only assumed---not proven---by \HP.

\setcounter{equation}{0}% Restart equation counter
\begin{figure*}[h]
    \centering
    \begin{align}
    % Empty
    \seval{\cdot}{u} &= [\cdot] \\
    % SingleField
    \sevalu{\fld\; ::\; \queries} &= \begin{cases}
    \resp{\texttt{coerce(\val)}} \; ::\; \sevalu{\queries}  & \mathit{u.property}(\fld) = \val \\
    \resp{\nval} \; :: \; \sevalu{\queries} & \sim
    \end{cases}\\
    % Nested field
    \sevalu{\nfld{\overline{\beta}} \; ::\; \queries} &=
    \begin{cases}
    \resp{\texttt{[} \mathit{map} (\lambda\; v_{i} \Rightarrow\; \seval{\overline{\beta}}{v_{i}})\; \mathit{neighbors(u)} \texttt{]}} \; :: \; \sevalu{\queries}  & \mathit{type(f)} \in L_{t} \text{and} \{v_{1}, \ldots, v_{k}\} = \{v_{i} \mid (u, f[\alpha], v_{i}) \in E\} \\
    (f:\{\seval{\subqueries{\beta}}{v}\})\; :: \; \sevalu{\queries}  & \mathit{type(f)} \notin L_{t} \text{and} (u, f[\alpha], v) \in E \\
    (f:null)\; :: \; \sevalu{\queries} & \mathit{type(f)} \notin L_{t} \text{and there is no } v \text{ s.t.} (u, f[\alpha], v) \in E \\
    \end{cases}\\
    %inline fragment
    \sevalu{\ifrag{t}{\overline{\beta}}\; ::\; \queries} &= \begin{cases}
    \sevalu{\overline{\beta} \mdoubleplus \queries} & \mathit{does\_fragment\_type\_apply_{\texttt{t}}(u.type)} = \texttt{true}\\
    \sevalu{\queries} & \sim
    \end{cases}
    \end{align}
    \caption{Simplified semantics for queries in normal form.}
    \label{fig:simpl_semantics}
\end{figure*}


First, we prove that the normalization procedure is correct \et{meaning? there are tons of definitions of correctness, so you need to be super clear} and produces queries in normal form, by proving separately that the resulting queries are grounded and non-redundant\footnote{Since we prove that grounded implies ground-typed normal form, we can also prove ground-typed normal form for the normalization function.\et{this whole story about g-t normal form makes more noise than necessary, I think}}. Both are proved by well-founded induction over the queries size\footnote{The notion of size includes the length of the list as well as the depth of the query tree.\et{this should be made clear in section 3, when you explain how you model queries. Just reading section 4, you jump between singular, list, and trees... confusing}} and auxiliary lemmas about subtyping.  We consider the case where the type in scope is an Object type \et{you use "object type" and "Object type" interchangeably, it's confusing} and the general case. 

\begin{minted}[escapeinside=||,mathescape=true]{coq}
Lemma normalize_are_grounded (s : wfGraphQLSchema)
                             (ty : Name)
                             (|$\varphi$| : seq Query) :
    is_object_type s ty ->
    are_grounded s ty (normalize s ty |$\varphi$|).

Lemma normalize_are_non_redundant (s : wfGraphQLSchema)
                                  (ty : Name)
                                  (|$\varphi$| : seq Query) :
    is_object_type s ty ->
    are_non_redundant (normalize s ty |$\varphi$|).

\end{minted}

Next, we prove normalization preserves the semantics of queries. To begin with, we prove the case where the type in context is the same as the type of the node where queries are being normalized. Lifting this to the top level, it corresponds to normalizing over the Query type and evaluating on the root node (whose type is the same, due to graph conformance). We then extend this notion to normalization over any type in context, \texttt{ty}\et{here you're using "ty" - ts or ty is good for me but be consistent throughout}, but with the restriction that the node's type must be subtype of \texttt{ty}. Once again, this is valid at top level over the Query type and the root node. Conformance of the graph also ensures that normalization and evaluation over neighboring nodes is preserved\et{why? I don't get it}. The proof also follows by well-founded induction over the queries size and auxiliary lemmas about graph conformance.

\begin{minted}[escapeinside=||,mathescape=true]{coq}
Lemma normalize_exec (s : wfGraphQLSchema)
                     (g : conformedGraph s)
                     (u : node)
                     (|$\varphi$| : seq Query) :
    u |\textbackslash|in g.(nodes) ->
    s, g |$\vdash$| |$\llbracket$| normalize s u.(ntype) |$\varphi$| |$\rrbracket$| in u with coerce =
    s, g |$\vdash$| |$\llbracket$| |$\varphi$| |$\rrbracket$| in u with coerce.

Theorem normalize_queries_exec (s : wfGraphQLSchema)
                               (g : conformedGraph s)
                               (u : node)
                               (ty : Name)
                               (|$\varphi$| : seq Query) :
    u |\textbackslash|in g.(nodes) ->
    u.(ntype) |\textbackslash|in get_possible_types s ty ->
    s, g |$\vdash$| |$\llbracket$| normalize_queries s ty |$\varphi$| |$\rrbracket$| in u with coerce =
    s, g |$\vdash$| |$\llbracket$| |$\varphi$| |$\rrbracket$| in u with coerce.

\end{minted}

This concludes our proofs of normalization and establish that the first premise used by \HP is correct in the context of our system.\et{you should mention the problems you discovered about \HP by doing this formalization}
% The next section continues with the second premise, namely the definition of a simplified version of the semantics and the proof of equivalence.

\subsection{Simplified semantics}

As proposed by \HP, one of the main properties of queries in normal form is that they produce non-redundant responses\et{is that the main motivation for HP to propose normalization in the first place? (if so, say it)}\td{They actually say "unique responses" - they don't define non-redundancy for responses.}\et{why change the name? unique or non-redundant?}, without the need of any collection and merger of fields. This property allows defining a second evaluation function $\ll \varphi \gg_{G}$, similar to the original (\S\ref{subsec:semantics}), but without any filtering and collecting of fields. Figure~\ref{fig:simpl_semantics} shows the simplified semantics's formal definition. Aliased cases\et{?} are not included due to space constraints.
\HP do not formally prove however that the simplified semantics are equivalent to the original, when considering normalized queries.

We define the simplified semantics of \HP, and prove that, for queries in normal form, both $\llbracket \varphi \rrbracket_{G}$ and $\ll \varphi \gg_{G}$ produce the same response. We do not include the complete definition---they can be found in files \texttt{QuerySemantics.v} and \texttt{QuerySemanticsLemmas.v}. The proof is once again performed by induction over the size of the queries. \et{any insight from the proofs?}

\begin{minted}[escapeinside=||,mathescape=true]{coq}
Theorem exec_equivalence (s : wfGraphQLSchema)
                         (g : conformedGraph s)
                         (u : node)
                         (|$\varphi$| : seq Query) :
    are_in_ground_typed_nf s |$\varphi$| ->
    are_non_redundant |$\varphi$| ->
    s, g |$\vdash$| |$\llbracket$| |$\varphi$| |$\rrbracket$| in u with coerce =
    s, g |$\vdash$| |$\ll$| |$\varphi$| |$\gg$| in u with coerce.
\end{minted}

\et{not useful conclusion paragraph---and not finished} This result concludes the normalization process. We have described our approach to proving both premises exploited by \HP. As mentioned earlier, these are fundamental for their complexity results over \gql queries but were not proven true. We believe our approach properly and rigorously addresses them. The following section discusses

\et{to consider: having a subsection 4.5 on Discussions/Lessons/Observations that gathers all the insights about this normalization story}
\et{this would make section 5 (which could be placed before section 4) a section dedicated to the discussions on the core formalization (section 3)}


